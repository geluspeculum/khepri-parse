/**
 * @fileOverview Khepri lexers.
 */
package (
    literal
    token
    inputElement
    lexer
    
    lex
    lexStream)
with
    import 'bennu::parse' parse#{
        always
        attempt
        binds
        bind
        choice
        eof
        getPosition
        enumeration
        extract
        many
        runState
        ParserState},
    import 'bennu::lang' {then},
    import 'nu-stream::stream' {'from': streamFrom},
    
    import 'khepri-ast::token' lexToken,
    import 'khepri-ast::position' {SourceLocation SourcePosition},
    
    import './boolean_lexer' {booleanLiteral},
    import './comment_lexer' {comment},
    import './identifier_lexer' {identifier},
    import './line_terminator_lexer' {lineTerminator},
    import './null_lexer' {nullLiteral},
    import './number_lexer' {numericLiteral},
    import './punctuator_lexer' {punctuator infixOperator prefixOperator},
    import './reserved_word_lexer' {reservedWord},
    import './string_lexer' {stringLiteral},
    import './whitespace_lexer' {whitespace},
    import './regular_expression_lexer' {regularExpressionLiteral}
in {

var makeToken := \type p ->
    p.map \ value -> [type, value];

var location := \start end ->
    new SourceLocation(
        start,
        end,
        start.file || end.file);

var buildToken = \p ->
    binds(
        enumeration(
            getPosition,
            p,
            getPosition),
        \start [type value] end ->
            always(
                type(
                    location(start, end),
                    value)));
/* Lexers
 ******************************************************************************/
var literalImpl = choice(
    makeToken(
        lexToken.StringToken.create,
        stringLiteral),
    makeToken(
        lexToken.RegularExpressionToken.create,
        regularExpressionLiteral),
    makeToken(
        lexToken.BooleanToken.create,
        booleanLiteral),
    makeToken(
        lexToken.NullToken.create,
        nullLiteral),
    makeToken(
        lexToken.NumberToken.create,
        numericLiteral));

var tokenImpl = choice(
    attempt makeToken(
        lexToken.IdentifierToken.create,
        identifier),
    literalImpl,
    makeToken(
        lexToken.KeywordToken.create,
        reservedWord),
    makeToken(
        \loc [base user] ->
            lexToken.PrefixOperatorToken.create(loc, base + user, base),
        prefixOperator),
    makeToken(
        \loc [base user] ->
            lexToken.InfixOperatorToken.create(loc, base + user, base),
        infixOperator),
    makeToken(
        lexToken.PunctuatorToken.create,
        punctuator));

var inputElementImpl = choice(
    makeToken(
        lexToken.CommentToken.create,
        comment),
    makeToken(
        lexToken.WhitespaceToken.create,
        whitespace),
    makeToken(
        lexToken.LineTerminatorToken.create,
        lineTerminator),
    tokenImpl);

/* Lexers
 ******************************************************************************/
/**
 * Literal lexer
 */
literal := buildToken(literalImpl);

/**
 * Token lexer.
 */
token := buildToken(tokenImpl);

/**
 * Input element lexer.
 * 
 * 
 */
inputElement = buildToken(inputElementImpl);

/**
 * Khepri source lexer.
 * 
 * Returns stream of lex tokesn
 */
lexer = then(
    many inputElement,
    eof);

/* Running
 ******************************************************************************/
var initialFilePosition := \file ->
    new SourcePosition(
        SourcePosition.initial.line,
        SourcePosition.initial.column,
        file);

/**
 * Tokenize a stream of khepri source characters.
 * 
 * @param input Nu stream of characters.
 * @param [file] {string} File name.
 */
lexStream := \input file -> 
    runState(
        lexer,
        new ParserState(
            input,
            initialFilePosition file));
    
/**
 * Tokenize a khepri source string.
 * 
 * @param input {string} Input.
 * @param [file] {string} File name.
 */
lex := \input file ->
    lexStream(
        streamFrom input,
        file);

}