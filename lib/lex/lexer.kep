/**
 * @fileOverview Khepri lexers.
 */
package (
    literal
    token
    inputElement
    lexer
    
    lex
    lexStream)
with
    import 'bennu::parse' parse#{
        always
        attempt
        binds
        bind
        choice
        eof
        getPosition
        enumeration
        extract
        many
        runState
        ParserState},
    import 'bennu::lang' {then},
    import 'nu-stream::stream' {'from': streamFrom},
    
    import 'khepri-ast::token' lexToken,
    import 'khepri-ast::position' {SourceLocation SourcePosition},
    
    import './boolean_lexer' {booleanLiteral},
    import './comment_lexer' {comment},
    import './identifier_lexer' {identifier, identifierName},
    import './line_terminator_lexer' {lineTerminator},
    import './null_lexer' {nullLiteral},
    import './number_lexer' {numericLiteral},
    import './punctuator_lexer' {punctuator},
    import './reserved_word_lexer' {reservedWord},
    import './string_lexer' {stringLiteral},
    import './whitespace_lexer' {whitespace},
    import './regular_expression_lexer' {regularExpressionLiteral}
in {

var makeToken := \type p ->
    p.map \ value -> [type, value];

var location := \start end ->
    new SourceLocation(
        start,
        end,
        start.file || end.file);

var buildToken = \p ->
    binds(
        enumeration(
            getPosition,
            p,
            getPosition),
        \start, [type value], end ->
            always(
                new type(
                    location(start, end),
                    value)));
/* Lexers
 ******************************************************************************/
var literalImpl = choice(
    makeToken(lexToken.StringToken, stringLiteral),
    makeToken(lexToken.RegularExpressionToken, regularExpressionLiteral),
    makeToken(lexToken.BooleanToken, booleanLiteral),
    makeToken(lexToken.NullToken, nullLiteral),
    makeToken(lexToken.NumberToken, numericLiteral));

var tokenImpl = choice(
    attempt <|
        makeToken(lexToken.IdentifierToken, identifier),
    attempt <|
        literalImpl,
    makeToken(lexToken.KeywordToken, reservedWord),
    makeToken(lexToken.PunctuatorToken, punctuator));

var inputElementImpl = choice(
    makeToken(lexToken.CommentToken, comment),
    makeToken(lexToken.WhitespaceToken, whitespace),
    makeToken(lexToken.LineTerminatorToken, lineTerminator),
    tokenImpl);

literal = buildToken(literalImpl);

token = buildToken(tokenImpl);

inputElement = buildToken(inputElementImpl);

lexer = then(
    many inputElement,
    eof);

/* Running
 ******************************************************************************/
var initialFilePosition = \file ->
    new SourcePosition(
        SourcePosition.initial.line,
        SourcePosition.initial.column,
        file);

/**
 * Tokenize a stream of khepri source characters.
 * 
 * @param input Nu stream of characters.
 * @param [file] {string} File name.
 */
lexStream := \input file -> 
    runState(
        lexer,
        new ParserState(
            input,
            initialFilePosition file));
    
/**
 * Tokenize a khepri source string.
 * 
 * @param input {string} Input.
 * @param [file] {string} File name.
 */
lex := \input file ->
    lexStream(
        streamFrom input,
        file);

}